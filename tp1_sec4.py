#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TP1 Section 4: Mappage Tonal et Encodage d'Affichage

Ce script:
1. Charge les images XYZ depuis ./images_intermediaires_sec3/*_camera_xyz.tiff
2. Applique l'ajustement de luminosit√© (√Ä IMPL√âMENTER)
3. Applique le mappage tonal:
   - Lin√©aire (impl√©ment√©)
   - Reinhard (√Ä IMPL√âMENTER)
4. Convertit XYZ vers sRGB lin√©aire (impl√©ment√©)
5. Applique l'OETF sRGB (impl√©ment√©)
6. Sauvegarde le JPEG final (impl√©ment√©)
7. Analyse les artefacts JPEG (√Ä IMPL√âMENTER)
8. Sauvegarde dans ./images_intermediaires_sec4/

Usage:
    python tp1_sec4.py --input-dir images_intermediaires_sec3 --output-dir images_intermediaires_sec4
"""

import glob
import os
import textwrap
from collections import defaultdict

import numpy as np
from PIL import Image
from matplotlib import pyplot as plt

from tp1_io import (
    load_tiff,
    save_tiff16,
    linear_to_srgb,
    xyz_to_linear_srgb,
    quantize_to_8bit,
)
from tp1_rapport import (
    html_document,
    section,
    subsection,
    figure,
    table,
    algorithm_box,
    formula_box,
    save_report,
    comparison_grid,
    create_tonemapping_curves_figure,
    create_tonemapping_comparison_figure,
    create_oetf_comparison_figure,
    create_dynamic_range_figure, find_edge_region,
    make_styled_paragraphs
)


# =============================================================================
# Ajustement de Luminosit√©
# =============================================================================


def adjust_brightness(xyz_image, percentile=99):
    """
    Ajuster la luminosit√© de l'image en normalisant au percentile donn√©.

    Mesure le percentile sp√©cifi√© du canal Y (luminance) et divise
    toute l'image par cette valeur pour normaliser la luminosit√©.

    Args:
        xyz_image: Image XYZ [H, W, 3]
        percentile: Percentile √† utiliser pour la normalisation (d√©faut: 99)

    Returns:
        Image XYZ avec luminosit√© ajust√©e
    """
    Y = xyz_image[:, :, 1]

    # Compute the percentile of luminance (excluding zeros/negatives)
    valid_Y = Y[Y > 0]
    if len(valid_Y) == 0:
        print("    Warning: No valid luminance values, skipping brightness adjustment")
        return xyz_image.copy()

    percentile_value = np.percentile(valid_Y, percentile)

    if percentile_value <= 0:
        print("    Warning: Percentile value <= 0, skipping brightness adjustment")
        return xyz_image.copy()

    # Divide the entire image by the percentile value
    adjusted = xyz_image / percentile_value

    print(f"    Brightness adjustment: divided by {percentile_value:.6f} (1st percentile)")

    return adjusted


# =============================================================================
# Op√©rateurs de Mappage Tonal
# =============================================================================


def tonemap_linear(xyz_image):
    """
    Mappage tonal lin√©aire (identit√©) - pas de compression.

    Les valeurs > 1 seront clipp√©es lors de la conversion finale.

    Args:
        xyz_image: Image XYZ [H, W, 3]

    Returns:
        Image XYZ (copie)
    """
    return xyz_image.copy()


def tonemap_reinhard(xyz_image):
    """
    Mappage tonal de Reinhard: L_out = L_in / (1 + L_in)

    Appliqu√© √† Y (luminance), X et Z sont mis √† l'√©chelle proportionnellement.

    R√©f√©rence: "Photographic Tone Reproduction for Digital Images" (2002)

    Args:
        xyz_image: Image XYZ [H, W, 3]

    Returns:
        Image XYZ avec mappage tonal appliqu√©
    """

    # Copier l'image pour ne pas modifier l'entr√©e
    result = xyz_image.copy()

    # 1. Extraire le canal Y (luminance)
    Y = xyz_image[:, :, 1]

    # 2. Appliquer la formule de Reinhard sur Y
    Y_mapped = Y / (1.0 + Y)

    # 3. Calculer le facteur d'√©chelle (√©viter division par z√©ro)
    scale = np.ones_like(Y)
    mask = Y > 0
    scale[mask] = Y_mapped[mask] / Y[mask]

    # 4. Appliquer ce ratio √† X, Y et Z
    result[:, :, 0] *= scale  # X
    result[:, :, 1] = Y_mapped  # Y (remplac√© directement)
    result[:, :, 2] *= scale  # Z

    return result


# =============================================================================
# Sauvegarde d'Images
# =============================================================================


def save_jpeg(img_8bit, filepath, quality=95):
    """
    Sauvegarder une image en JPEG.

    Args:
        img_8bit: Image uint8 [H, W, 3]
        filepath: Chemin de sortie
        quality: Qualit√© JPEG (1-100, d√©faut: 95)
    """
    Image.fromarray(img_8bit, mode="RGB").save(filepath, "JPEG", quality=quality)
    print(f"  Saved JPEG: {filepath}")


def save_png(img_8bit, filepath):
    """
    Sauvegarder une image en PNG (sans perte).

    Args:
        img_8bit: Image uint8 [H, W, 3]
        filepath: Chemin de sortie
    """
    Image.fromarray(img_8bit, mode="RGB").save(filepath, "PNG")
    print(f"  Saved PNG: {filepath}")


# =============================================================================
# Analyse des artefacts JPEG
# =============================================================================

def analyze_jpeg_artifacts(img_8bit, output_dir, basename, qualities=(95, 75, 50, 25)):
    """
    Analyse des tailles de fichiers JPEG par rapport √† un PNG de r√©f√©rence (sans perte).

    Args:
        img_8bit: Image sRGB uint8 [H, W, 3], 0-255
        output_dir: R√©pertoire o√π sauvegarder les JPEG/PNG
        basename: Nom de base pour les fichiers
        qualities: Liste de qualit√©s JPEG √† tester

    Returns:
        dict avec :
            - jpeg_sizes_Ko : {quality: size_in_Ko}
            - png_path      : chemin du PNG de r√©f√©rence
    """
    os.makedirs(output_dir, exist_ok=True)

    # PNG de r√©f√©rence (sans perte)
    png_path = os.path.join(output_dir, f"{basename}_reference.png")
    save_png(img_8bit, png_path)

    sizes = {}

    for q in qualities:
        jpeg_path = os.path.join(output_dir, f"{basename}_q{q}.jpg")
        save_jpeg(img_8bit, jpeg_path, quality=q)

        # Taille du fichier en Ko
        sizes[q] = os.path.getsize(jpeg_path) / 1024.0

    print("  Analyse JPEG termin√©e (tailles uniquement)")

    return {
        "jpeg_sizes_Ko": sizes,
        "png_path": png_path,
    }


def plot_global_jpeg_size_vs_quality(
        global_jpeg_sizes,
        global_png_sizes,
        output_path,
        title="Taille JPEG vs Qualit√© (moyenne sur toutes les images)",
):
    """
    Trace un graphique global taille JPEG vs qualit√© (moyenne sur toutes les images).

    Args:
        global_jpeg_sizes: dict {quality: [sizes_in_Ko]}
        output_path: chemin de sauvegarde du graphique
        title: titre optionnel
    """
    if not global_jpeg_sizes:
        print("  Aucune donn√©e JPEG globale √† tracer.")
        return

    qualities = sorted(global_jpeg_sizes.keys())
    mean_sizes = [np.mean(global_jpeg_sizes[q]) for q in qualities]
    std_sizes = [np.std(global_jpeg_sizes[q]) for q in qualities]

    mean_png_size = np.mean(global_png_sizes)
    std_png_size = np.std(global_png_sizes)

    fig, ax = plt.subplots(figsize=(6, 4))

    # Courbe JPEG
    ax.plot(
        qualities,
        mean_sizes,
        "o-",
        color="tab:blue",
        label="Taille moyenne JPEG",
    )

    ax.fill_between(
        qualities,
        np.array(mean_sizes) - std_sizes,
        np.array(mean_sizes) + std_sizes,
        alpha=0.25,
        color="tab:blue",
        label="JPEG ¬± √©cart-type",
    )

    # Ligne PNG de r√©f√©rence
    ax.axhspan(
        mean_png_size - std_png_size,
        mean_png_size + std_png_size,
        color="tab:green",
        alpha=0.2,
        label="PNG ¬± √©cart-type",
    )
    ax.axhline(
        mean_png_size,
        color="tab:green",
        linestyle="--",
        linewidth=2,
        label="Taille moyenne PNG",
    )

    ax.set_xlabel("Qualit√© JPEG")
    ax.set_ylabel("Taille du fichier (Ko)")
    ax.set_xticks(qualities)
    ax.set_title(title)
    ax.grid(True, alpha=0.3)
    ax.legend()

    plt.tight_layout()
    plt.savefig(output_path, dpi=150)
    plt.close(fig)

    print(f"  Graphique global JPEG sauvegard√©: {output_path}")


def create_jpeg_zoom_figure(images_dict, output_path, edge_pos=None, center_pos=None, zoom_size=150, title=""):
    """
    Cr√©e une figure pour visualiser les artefacts JPEG avec 3 rang√©es :
    1) Image enti√®re
    2) R√©gion avec contours
    3) Centre de l'image

    Args:
        images_dict : dict {nom: chemin_fichier}
        output_path : chemin de sauvegarde
        edge_pos : (y, x) position centrale de la r√©gion avec contours (optionnel)
        center_pos : (y, x) position centrale de la r√©gion centrale (optionnel)
        zoom_size : taille des r√©gions zoom√©es
        title : titre optionnel
    """
    num_images = len(images_dict)
    fig, axes = plt.subplots(3, num_images, figsize=(4 * num_images, 12))
    if num_images == 1:
        axes = np.expand_dims(axes, axis=1)  # pour que axes[i, j] fonctionne m√™me avec 1 image

    def clean_axes(ax):
        ax.set_xticks([])
        ax.set_yticks([])
        for spine in ax.spines.values():
            spine.set_visible(False)

    for col, (name, path) in enumerate(images_dict.items()):
        img = np.array(Image.open(path))
        H, W = img.shape[:2]

        # 1) Image enti√®re
        axes[0, col].imshow(img)
        axes[0, col].set_title(name, fontweight="bold")
        if col == 0:
            axes[0, col].set_ylabel("Image enti√®re", fontweight="bold")
        clean_axes(axes[0, col])

        # 2) R√©gion avec contours
        if edge_pos is not None:
            y, x = edge_pos
            y1, y2 = max(0, y - zoom_size // 2), min(H, y + zoom_size // 2)
            x1, x2 = max(0, x - zoom_size // 2), min(W, x + zoom_size // 2)
            axes[1, col].imshow(img[y1:y2, x1:x2], interpolation="nearest")
            if col == 0:
                axes[1, col].set_ylabel("R√©gion avec contours", fontweight="bold")
            clean_axes(axes[1, col])

        # 3) Centre de l'image
        if center_pos is not None:
            y, x = center_pos
        else:
            y, x = H // 2, W // 2
        y1, y2 = max(0, y - zoom_size // 2), min(H, y + zoom_size // 2)
        x1, x2 = max(0, x - zoom_size // 2), min(W, x + zoom_size // 2)
        axes[2, col].imshow(img[y1:y2, x1:x2], interpolation="nearest")
        if col == 0:
            axes[2, col].set_ylabel("Centre de l'image", fontweight="bold")
        clean_axes(axes[2, col])

    if title:
        fig.suptitle(title, fontsize=14, fontweight="bold", y=1.02)

    fig.subplots_adjust(left=0.06)
    plt.tight_layout()
    fig.savefig(output_path, dpi=150, bbox_inches="tight", facecolor="white")
    plt.close(fig)
    print(f"  Saved JPEG zoom figure: {output_path}")


# =============================================================================
# Analyse de Plage Dynamique
# =============================================================================


def analyze_dynamic_range(image_linear):
    """Analyser l'√©cr√™tage des hautes lumi√®res et l'√©crasement des ombres."""
    lum = (
            0.2126 * image_linear[:, :, 0]
            + 0.7152 * image_linear[:, :, 1]
            + 0.0722 * image_linear[:, :, 2]
    )

    highlight_pct = np.sum(lum >= 0.99) / lum.size * 100
    shadow_pct = np.sum(lum <= 0.01) / lum.size * 100

    valid = lum[lum > 0]
    if len(valid) > 0:
        min_lum, max_lum = np.percentile(valid, 1), np.percentile(valid, 99)
        dr_stops = np.log2(max_lum / min_lum) if min_lum > 0 else 0
    else:
        dr_stops = 0

    return {
        "highlight_clipped_percent": highlight_pct,
        "shadow_crushed_percent": shadow_pct,
        "dynamic_range_stops": dr_stops,
        "min_luminance": float(np.min(lum)),
        "max_luminance": float(np.max(lum)),
        "mean_luminance": float(np.mean(lum)),
    }


# =============================================================================
# G√©n√©ration du Rapport HTML
# =============================================================================


def generate_report(results, output_dir):
    """
    G√©n√©rer un rapport HTML template pour toutes les sections du TP1.
    
    Cr√©e un rapport complet avec:
    - Section 1: Chargement et compr√©hension des donn√©es RAW
    - Section 2: D√©matri√ßage (Demosaicking)
    - Section 3: Balance des Blancs (White Balance)
    - Section 4: Mappage tonal et encodage d'affichage
    
    Inclut toutes les figures g√©n√©r√©es et des espaces "√Ä remplir" pour l'√©tudiant.
    """
    # D√©finir les r√©pertoires de sortie pour chaque section
    # Si output_dir est "images_intermediaires_sec4", base_dir sera le r√©pertoire parent
    if "images_intermediaires_sec" in os.path.basename(output_dir):
        base_dir = os.path.dirname(output_dir) or "."
    else:
        base_dir = output_dir

    sec1_dir = os.path.join(base_dir, "images_intermediaires_sec1")
    sec2_dir = os.path.join(base_dir, "images_intermediaires_sec2")
    sec3_dir = os.path.join(base_dir, "images_intermediaires_sec3")
    sec4_dir = output_dir

    # Obtenir la liste des basenames (noms de fichiers sans extension)
    basenames = [result["basename"] for result in results] if results else []

    # Si aucun r√©sultat, chercher les fichiers dans les r√©pertoires
    if not basenames:
        # Chercher dans sec1
        tiff_files = glob.glob(os.path.join(sec1_dir, "*.tiff"))
        basenames = [os.path.splitext(os.path.basename(f))[0] for f in tiff_files if "zoom" not in f]
        basenames = list(set(basenames))  # D√©dupliquer

    # Limiter √† 2 images d'exemple pour rendre le rapport plus court
    basenames = sorted(basenames)[:2]
    content = ""

    # =============================================================================
    # SECTION 1: Chargement et Compr√©hension des Donn√©es RAW
    # =============================================================================
    sec1_content = ""

    # Texte d'introduction pour la section 1
    sec1_raw_intro_text = textwrap.dedent("""
    Le format RAW contient les mesures brutes du capteur photo, sans traitement ni compression. 
    Dans le pr√©sent TP, la format RAW utilis√© est le DNG (Digital Negative).
    
    Le motif de Bayer est une matrice de filtres de couleur o√π chaque pixel n'enregistre qu'un seul canal de couleur (rouge, vert ou bleu). 
    C'est ce qui permet de capter plusieurs couleurs diff√©rentes en m√™me temps.
    Les couleurs sont altern√©es et le vert apparait deux fois plus souvent que les autres couleurs. 
    √Ä partir de ce filtre, on peut reconstruire l‚Äôimage couleur par interpolation.
    
    La normalisation des donn√©es brutes ram√®ne les valeurs de couleurs capt√©es entre 0 et 1 pour faciliter ensuite le traitement, 
    et permettre de comparer des images provenant de capteurs diff√©rents. 
    """)

    sec1_content += subsection(
        "Introduction",
        make_styled_paragraphs(sec1_raw_intro_text)
    )

    for basename in basenames:
        sec1_img_content = ""

        # Figure: Zoom sur la mosa√Øque Bayer
        zoom_path = os.path.join(sec1_dir, f"{basename}_zoom16x16.png")
        if os.path.exists(zoom_path):
            sec1_img_content += subsection(
                f"R√©gion 16√ó16 de la mosa√Øque - {basename}",
                figure(f"../images_intermediaires_sec1/{basename}_zoom16x16.png",
                       "Zoom sur une r√©gion 16√ó16 montrant les valeurs normalis√©es et le motif de Bayer color√©.")
            )

        if sec1_img_content:
            sec1_content += section(f"Image: {basename}", sec1_img_content)

    # Analyse et observations
    sec1_raw_analyse_text = textwrap.dedent("""
Les m√©tadonn√©es de chaque photo informent sur le motif de Bayer utilis√©, la profondeur de bits, les dimensions et 
l'orientation. De plus, on peut r√©cup√©rer les valeurs de niveau de noir et de niveau de blanc. 
On a aussi les valeurs fournies par la cam√©ra pour faire la balance des blancs. 
Finalement, on a la matrice RGB->XYZ sp√©cifique √† la cam√©ra (pour passer d'une "couleur cam√©ra" √† une couleur normalis√©e), 
ainsi que la matrice de couleur, servant √† convertir les valeurs RAW normalis√©es du capteur vers un espace couleur standard (pour visualiser √† l'√©cran).
Je constate que ces caract√©ristiques sont toutes variables √† l'int√©rieur du set de photos utilis√©es. 
Il faut donc que les algorithmes utilis√©s fonctionnent peu importe ces caract√©ristiques. 

Les motifs de Bayer (RGGB, BGGR, GRBG, etc.) montrent comment les pixels capturent alternativement les couleurs, 
toujours avec le vert pr√©sent deux fois plus que les autres couleurs.

Les niveaux de noir sont les valeurs enregistr√©es par le capteur quand il ne re√ßoit aucune lumi√®re 
et les niveaux de blanc sont leurs valeurs de saturation maximale. Ces valeurs d√©pendent de la profondeur de bits.
On se sert directement de ces valeurs minimales et maximales pour la normalisation.

Les images pr√©sent√©es ci-dessus permettent de visualiser la conversion d'une mosaique brute, d'apr√®s le motif de Bayer associ√©, en mosaique color√©e. 
On voit clairement que chaque pixel ne contient qu‚Äôune seule composante de couleur, 
√† des niveaux variables, et que les pixels verts apparaissent deux fois plus fr√©quemment que les pixels rouges et bleux.
    """)

    sec1_content += subsection(
        "Analyse et observations",
        make_styled_paragraphs(sec1_raw_analyse_text)
    )

    content += section("Section 1: Chargement et Compr√©hension des Donn√©es RAW", sec1_content, icon="üì∑")

    # =============================================================================
    # SECTION 2: D√©matri√ßage (Demosaicking)
    # =============================================================================
    sec2_content = ""

    # Texte d'introduction pour la section 2
    sec2_raw_intro_text = textwrap.dedent("""
    Le d√©matri√ßage consiste √† reconstruire une image couleur compl√®te √† partir de la mosa√Øque Bayer mono-canal.
    Puisque chaque pixel n'enregistre qu'une seule couleur, les deux autres doivent √™tre interpol√©es √† partir des pixels voisins.
    Pour ce faire, plusieurs m√©thodes existent, dont la m√©thode bilin√©aire et la m√©thode Malvar-He-Cutler.
    
    La m√©thode bilin√©aire interpole simplement les couleurs manquantes √† partir de la moyenne des pixels voisins de m√™me couleur, 
    ce qui est simple et rapide, mais reconnu pour g√©n√©rer des artefacts comme le moir√© et les contours color√©s.  

    La m√©thode Malvar-He-Cutler utilise des filtres lin√©aires optimis√©s pour r√©duire ces artefacts et am√©liorer la fid√©lit√© des couleurs, 
    donnant g√©n√©ralement un r√©sultat plus propre. Le principe derri√®re les filtres est d'utiliser l'information sur les contours 
    pour √©viter de les traverser avec une couleur.
    """)

    sec2_content += subsection(
        "Introduction",
        make_styled_paragraphs(sec2_raw_intro_text)
    )

    for basename in basenames:
        sec2_img_content = ""

        # Figure: Comparaison des m√©thodes
        comp_path = os.path.join(sec2_dir, f"{basename}_comparison.png")
        if os.path.exists(comp_path):
            sec2_img_content += subsection(
                f"Comparaison des m√©thodes - {basename}",
                figure(f"../images_intermediaires_sec2/{basename}_comparison.png",
                       "Comparaison des m√©thodes de d√©matri√ßage")
            )

        # Figure: Zoom sur les artefacts
        zoom_path = os.path.join(sec2_dir, f"{basename}_zoom.png")
        if os.path.exists(zoom_path):
            sec2_img_content += subsection(
                f"Zoom sur les artefacts - {basename}",
                figure(f"../images_intermediaires_sec2/{basename}_zoom.png",
                       "Recadrages montrant les artefacts de contour")
            )

        if sec2_img_content:
            sec2_content += section(f"Image: {basename}", sec2_img_content)

    # Analyse et observations
    sec2_raw_analyse_text = textwrap.dedent("""
INTERPR√âTATION VISUELLE DES IMAGES OBTENUES
Il y a peu de diff√©rences entre les r√©sultats obtenus avec chacune des m√©thodes. 
Ces minces diff√©rences ne sont perceptibles qu'en zoomant sur les zones avec de forts contrastes. 
On voit alors que l'extrapolation bilin√©aire donne un r√©sultat avec des contours plus adoucis, 
alors que les contours obtenus avec Malvar sont plus d√©finis.

Peu importe la m√©thode utilis√©e, on voit parfois apparaitre des pixels de couleur (effet de Moir√©) √† des endroits 
de haute luminosit√© (couleur blanche). L'interpolation bilin√©aire permet de "lisser" ces pixels de couleur, 
et donc les att√©nue, comparativement √† la m√©thode Malvac-He-Cutler.

INTERPR√âTATION DES M√âTRIQUES: TEMPS
L'interpolation bilin√©aire est toujours plus rapide que la m√©thode Malvar-He-Cutler, 
probablement en raison des kernels de convolution, qui sont plus gros. 
Donc la faible am√©lioration de la qualit√© se fait au d√©triment de la vitesse.

INTERPR√âTATION DES M√âTRIQUES: PSNR
Le PSNR est une m√©trique qui informe sur la diff√©rence de valeur pixel par pixel entre deux images. 
Il s'exprime en d√©cibels (dB). Plus la valeur est √©lev√©e, plus l'image trait√©e est proche de l'originale.

Selon la litt√©rature, pour des donn√©es 8 bits, les valeurs de PSNR oscillent g√©n√©ralement entre 30 et 50 dB. 
Pour des donn√©es 16 bits, les valeurs de PSNR oscillent g√©n√©ralement entre 60 et 80 dB. 
Nos r√©sultats vont de 40.82 dB √† 57.08 dB, pour des images majoritairement de 12 et 14 bits, et une seule image √† 16 bits (pelican).

Dans notre cas, comme le PSNR se calcule par rapport √† l'image avec interpolation bilin√©aire, 
mon interpr√©tion de la m√©trique est que plus elle est faible, plus la diff√©rence entre les deux algorithmes est marqu√©e 
(on ne peut que comparer des images ayant le m√™me nombre de bits). La PSNR la plus √©lev√©e est pour pelican, 
ce qui est logique puisque J'ai toutefois eu du mal √† voir une corr√©lation entre la valeur de la m√©trique (qui varie entre 40.82 et 57.08) 
et la similarit√© entre les r√©sultats.

INTERPR√âTATION DES M√âTRIQUES: SSIM
Le SSIM repose sur un indice de similarit√© structurelle entre deux images, en int√©grant le contraste de l'image, 
les diff√©rences structurelles et la luminosit√©. Plus il est pr√®s de 1, plus deux images sont similaires. 
Dans notre cas, les valeurs de SSIM (Structural Similarity Index) sont tr√®s pr√®s de 1, 
ce qui indique que la structure globable de l'image est presque identique entre les algorithmes.

R√âF√âRENCE
R√©f√©rence pour la compr√©hension des m√©triques PSNR et SSIM: 
Sara, U. , Akter, M. and Uddin, M. (2019) Image Quality Assessment through FSIM, SSIM, MSE and PSNR‚ÄîA Comparative Study. Journal of Computer and Communications, 7, 8-18. doi: 10.4236/jcc.2019.73002. 
Disponible √† https://www.scirp.org/journal/paperinformation?paperid=90911.
        """)

    sec2_content += subsection(
        "Analyse et observations",
        make_styled_paragraphs(sec2_raw_analyse_text)
    )

    content += section("Section 2: D√©matri√ßage (Demosaicking)", sec2_content, icon="üé®")

    # =============================================================================
    # SECTION 3: Balance des Blancs (White Balance)
    # =============================================================================
    sec3_content = ""

    # Texte d'introduction pour la section 3
    sec3_raw_intro_text = textwrap.dedent("""
Les images RAW enregistrent fid√®lement la couleur de la lumi√®re telle qu‚Äôelle arrive sur le capteur, 
laquelle d√©pend fortement du type d‚Äô√©clairage (ex: chaud ou froid).
La balance des blancs consiste alors √† corriger les canaux RVB afin que les surfaces neutres restent neutres dans l‚Äôimage finale. 
Plusieurs algorithmes peuvent √™tre utilis√©s pour y arriver. J'en ai test√© 2 dans le pr√©sent TP, que j'ai compar√© √† la balance des blancs cam√©ra.

L‚Äôalgorithme de la r√©gion neutre repose sur l‚Äôidentification d‚Äôune zone suppos√©e grise ou blanche dans l‚Äôimage. 
Cette zone pourrait √™tre d√©termin√©e manuellement (par un clic), mais pour ce TP, elle est d√©termin√©e automatiquement avec un algorithme. 
Cet algorithme consiste √† parcourir l'image √† intervalles r√©guliers (20 pixels) 
et analyser √† chaque endroit la luminosit√© (pour √©carter les zones trop sombres) 
et la neutralit√© de la couleur (en cherchant le plus petit √©cart-type entre les composantes R, G et B). On cherche la zone la plus neutre possible.
Les gains des canaux RVB sont ensuite ajust√©s pour rendre cette zone compl√®tement neutre, ce qui donne de bons r√©sultats lorsque la d√©tection est correcte,
mais peut th√©oriquement √©chouer en l‚Äôabsence de r√©f√©rence r√©ellement neutre.

L‚Äôalgorithme Grey World suppose que la moyenne des couleurs de l‚Äôimage doit √™tre grise (neutre).
Il √©quilibre les canaux RVB en fonction de cette hypoth√®se, ce qui le rend simple et efficace sur des sc√®nes vari√©es,
mais th√©oriquement peu fiable pour des images domin√©es par une couleur particuli√®re.

La balance des blancs cam√©ra s‚Äôappuie sur des mod√®les du capteur et des pr√©r√©glages li√©s aux conditions d‚Äô√©clairage. 
Les param√®tres √† utiliser dans les calculs sont fournis par les m√©tadonn√©es des photos.
Elle est rapide et robuste dans la majorit√© des cas, mais reste th√©oriquement limit√©e face √† des √©clairages complexes ou non standards.
    """)

    sec3_content += subsection(
        "Introduction",
        make_styled_paragraphs(sec3_raw_intro_text)
    )

    for basename in basenames:
        sec3_img_content = ""

        # Figure: Comparaison des m√©thodes
        comp_path = os.path.join(sec3_dir, f"{basename}_comparison.png")
        if os.path.exists(comp_path):
            sec3_img_content += subsection(
                f"Comparaison des m√©thodes - {basename}",
                figure(f"../images_intermediaires_sec3/{basename}_comparison.png",
                       "Comparaison des m√©thodes de balance des blancs")
            )

        # Figure: Conversion XYZ
        xyz_path = os.path.join(sec3_dir, f"{basename}_xyz_comparison.png")
        if os.path.exists(xyz_path):
            sec3_img_content += subsection(
                f"Conversion XYZ - {basename}",
                figure(f"../images_intermediaires_sec3/{basename}_xyz_comparison.png",
                       "Images converties en XYZ puis reconverties en sRGB")
            )

        if sec3_img_content:
            sec3_content += section(f"Image: {basename}", sec3_img_content)

        # Analyse et observations
        sec3_raw_analyse_text = textwrap.dedent("""
    COMPARAISON VISUELLE DES DIFF√âRENTES M√âTHODES DE BALANCE DES BLANCS ET DISCUSSION SUR LES MULTIPLICATEURS CALCUL√âS
    Sur certaines photos, les trois m√©thodes donnent un r√©sultat presqu'identique (par exemple, a0011-DSC_0082 - image d√©sertique). 
    Probablement que c'est parce que les couleurs de la photo originale sont majoritairement neutres et les canaux R, G et B sont relativement √©quilibr√©es.
   
    Sur d'autres photos, les r√©sultats sont vraiment diff√©rents selon la m√©thode. 
    Par exemple, sur l'image a0026-kme_391 (le tunnel), plut√¥t monochrome, la photo originale est jaun√¢tre. 
    Auto Neutre reste jaun√¢tre, probablement car aucune zone de la photo n'est vraiment neutre, ce qui fait que la r√©gion utilis√©e pour le recalibrage est jaun√¢tre.
    Grey World devient grisatre, car la moyenne de la sc√®ne n'est probablement pas grise. 
    La m√©thode compense en r√©duisant les canaux dominants (R et G), ce qui donne une image grisatre.
    Finalement, avec la m√©thode Cam√©ra, la photo devient orang√©, ce qui se rapproche probablement plus du rendu "naturel".
    
    Globalement, la m√©thode Grey World fonctionne parfois, mais lorsqu'elle se trompe, elle donne des r√©sultats tr√®s erron√©s (par exemple, une abeille qui devient bleu). 
    Je dirais que c'est la moins fiable des trois. 
    
    Auto Neutre n'est pas non plus tr√®s fiable. Probablement qu'en cliquant manuellement, ce serait plus fastidieux, mais √ßa donnerait de meilleurs r√©sultats.

    La m√©thode Cam√©ra semble √™tre la plus fiable sur des conditions d'√©clairage vari√©es.

    EXPLICATION DE LA CONVERSION VERS L'ESPACE XYZ
    Apr√®s le d√©matri√ßage, l'espace de couleur est "RGB de la cam√©ra", qui n'est pas un espace standard. 
    Le manufacturier donne la matrice de conversion vers XYZ.
    La conversion vers l‚Äôespace XYZ permet de repr√©senter les couleurs de mani√®re ind√©pendante du dispositif, 
    facilitant ensuite la conversion vers le format de notre choix (par exemple sRGB) tout en respectant les standards colorim√©triques.
    Ci-dessus, on voit notamment les images converties en XYZ, puis reconverties en sRGB pour permettre de les afficher. 
    Le rendu visuel est diff√©rent, car la reconversion en sRGB n√©cessite des ajustements, surtout parfois des couleurs "tronqu√©es" et une correction gamma.
            """)
    sec3_content += subsection(
        "Analyse et observations",
        make_styled_paragraphs(sec3_raw_analyse_text)
    )

    content += section("Section 3: Balance des Blancs (White Balance)", sec3_content, icon="‚ö™")

    # =============================================================================
    # SECTION 4: Mappage Tonal et Encodage d'Affichage
    # =============================================================================
    sec4_content = ""

    # Texte d'introduction pour la section 4
    sec4_raw_intro_text = textwrap.dedent("""
    Le mappage tonal est n√©cessaire pour afficher correctement une image dont la plage dynamique d√©passe celle des √©crans.
    Il compresse les valeurs lin√©aires captur√©es par le capteur en valeurs adapt√©es √† l‚Äôaffichage, en pr√©servant d√©tails et contraste.
    
    Afin de pr√©parer l'image pour le mappage tonal, il faut d'abord ajuster sa luminosit√©, 
    pour exclure des futurs calculs les valeurs extr√™mement lumineuses, qui seraient aberrantes. 
    Dans ce TP, la mani√®re de faire a √©t√© d'utiliser le 99·µâ percentile d'intensit√© pour diviser les images par cette valeur.

    Ensuite, plusieurs op√©rateurs sont possibles. Ils peuvent √™tre lin√©aires (simple normalisation, rapide mais √©crase les hautes lumi√®res) 
    ou Reinhard (non lin√©aire, compresse les hautes lumi√®res tout en conservant les d√©tails dans les ombres).
    
    L‚ÄôOETF sRGB applique une correction gamma pour adapter les valeurs lin√©aires √† la perception humaine, 
    renfor√ßant la luminosit√© per√ßue dans les tons moyens.
    
    L‚Äôanalyse de la plage dynamique permet d‚Äô√©valuer si les d√©tails dans les zones tr√®s claires 
    ou tr√®s sombres sont pr√©serv√©s et si le mappage tonal est efficace.
        """
                                          )
    sec4_content += subsection(
        "Introduction",
        make_styled_paragraphs(sec4_raw_intro_text)
    )

    # Concepts et algorithmes
    algorithms = algorithm_box(
        "A) Ajustement de luminosit√©",
        "<p>Division par le 99e percentile. <strong>√Ä IMPL√âMENTER</strong></p>",
    )
    algorithms += algorithm_box(
        "B) Mappage tonal",
        "<p><b>Lin√©aire:</b> Pas de compression.</p>"
        "<p><b>Reinhard:</b> <code>L_out = L_in / (1 + L_in)</code>. <strong>√Ä IMPL√âMENTER</strong></p>",
    )
    algorithms += algorithm_box(
        "C) Conversion XYZ ‚Üí sRGB",
        "<p>Matrice standard D65 suivie de l'OETF sRGB. <strong>IMPL√âMENT√â</strong></p>",
    )
    algorithms += algorithm_box(
        "D) OETF sRGB",
        formula_box("sRGB = 1.055 √ó lin√©aire^(1/2.4) ‚àí 0.055")
        + "<p><strong>IMPL√âMENT√â</strong></p>",
    )
    algorithms += algorithm_box(
        "E) Analyse des artefacts JPEG",
        "<p>Sauvegarde en diff√©rentes qualit√©s et analyse des artefacts. <strong>√Ä IMPL√âMENTER PAR L'√âTUDIANT</strong></p>",
    )

    sec4_content += subsection("Concepts et algorithmes", algorithms)

    # Figure: Courbes de mappage tonal
    curves_path = os.path.join(sec4_dir, "tonemapping_curves.png")
    if os.path.exists(curves_path):
        sec4_content += subsection(
            "Courbes de mappage tonal",
            figure("tonemapping_curves.png", "Comparaison des courbes de r√©ponse")
        )

    # Figures pour chaque image
    # Utiliser results si disponible, sinon utiliser basenames
    # Filtrer pour ne garder que les 2 images s√©lectionn√©es
    if results:
        images_to_process = [r for r in results if r["basename"] in basenames]
    else:
        images_to_process = [{"basename": bn} for bn in basenames]

    for result in images_to_process:
        basename = result["basename"]
        dr = result.get("dynamic_range", {})

        sec4_img_content = ""

        # Figure: Comparaison des op√©rateurs
        comp_path = os.path.join(sec4_dir, f"{basename}_tonemapping_comparison.png")
        if os.path.exists(comp_path):
            sec4_img_content += subsection(
                "Comparaison des op√©rateurs",
                figure(
                    f"{basename}_tonemapping_comparison.png",
                    "Comparaison: Lin√©aire, Reinhard",
                ),
            )

        # Figure: Avant/Apr√®s OETF
        oetf_path = os.path.join(sec4_dir, f"{basename}_oetf_comparison.png")
        if os.path.exists(oetf_path):
            sec4_img_content += subsection(
                "Avant/Apr√®s OETF",
                figure(
                    f"{basename}_oetf_comparison.png",
                    "L'OETF encode les valeurs lin√©aires pour l'affichage",
                ),
            )

        # Figure: Image finale
        final_path = os.path.join(sec4_dir, f"{basename}_final.jpg")
        if os.path.exists(final_path):
            sec4_img_content += subsection(
                "Image finale",
                figure(f"{basename}_final.jpg", "Image JPEG finale (qualit√© 95)"),
            )

        # Figure: Plage dynamique
        dr_path = os.path.join(sec4_dir, f"{basename}_dynamic_range.png")
        if os.path.exists(dr_path):
            dr_table = ""
            if dr:
                dr_table = table(
                    ["M√©trique", "Valeur"],
                    [
                        [
                            "Plage dynamique",
                            f"{dr.get('dynamic_range_stops', 0):.1f} stops",
                        ],
                        [
                            "Hautes lumi√®res √©cr√™t√©es",
                            f"{dr.get('highlight_clipped_percent', 0):.2f}%",
                        ],
                        ["Ombres √©cras√©es", f"{dr.get('shadow_crushed_percent', 0):.2f}%"],
                    ],
                )
            sec4_img_content += subsection(
                "Plage dynamique",
                figure(
                    f"{basename}_dynamic_range.png", "Analyse des hautes lumi√®res et ombres"
                ) + dr_table,
            )

        if sec4_img_content:
            sec4_content += section(basename, sec4_img_content)

        # Analyse et observations
        sec4_raw_analyse_text = textwrap.dedent("""
        COMPARAISON DES R√âSULTATS DES DIFF√âRENTS OP√âRATEURS DE MAPPAGE TONAL (VISUEL, PLAGE DYNAMIQUE)
        Sur les images d√©j√† bien expos√©es ou peu contrast√©es (par exemple, a0011-DSC_0082), Reinhard, en compressant les tons moyens-haut, 
        cr√©e un effet d'aplanissement peu int√©ressant. D'ailleurs, on observe bien sur les histogramme la compression de la plage des couleurs.
        Dans ces cas, l'op√©rateur lin√©aire donne un meilleur r√©sultat.
        
        Toutefois, pour des images plus contrast√©es comme celle o√π on voit directement le soleil (a0563-IMG_0286), 
        le r√©sultat est un peu plus beau (moins √©blouissant) avec Reinhard.
        
        J'en conclus que les images n'√©taient pas HDR (√† grande plage de luminance), donc que la compression de la plage des couleurs n'est pas n√©cessaire.

        IMPACT DE L'OETF SUR L'APPARENCE DE L'IMAGE
        L‚Äôapplication de l‚ÄôOETF sRGB modifie significativement l‚Äôapparence de l‚Äôimage en augmentant la luminosit√© per√ßue des tons moyens, 
        rendant l‚Äôimage plus naturelle √† l‚Äô√©cran. On percoit ainsi mieux, par exemple, les d√©tails des zones sombres. 
        
        ANALYSE DE LA PLAGE DYNAMIQUE ET DES ZONES √âCRET√âES/√âCRAS√âES
        Aucune des images n'a de hautes lumi√®res √©cr√™t√©es, c'est √† dire de pixels avec une luminance ‚â• 0.99. 
        Ces pixels tr√®s lumineux auraient √©t√© des zones compl√®tement blanches perdant du d√©tail. C'est donc une bonne chose.
        
        Quant aux ombres √©cras√©es, il s'agit des pixels dont la luminance ‚â§ 0.01, donc qui cr√©e une perte de d√©tails dans les zones sombres.
        Certaines photos en comportent une minime quantit√©.
        Si on exclut une photo des √©toiles dans l'espace en comportant 1.94% (ce qui parait normal √©tant donn√© que c'est l'espace..), 
        le maximum est de 0.66%, ce qui est minime. Les photos comportent en g√©n√©ral beaucoup de zones sombres (visible par les pixels bleus sur les images de Plage dynamique, 
        qui repr√©sentent tous les pixels dont la luminance est ‚â§ 0.05), donc on peut en conclure que c'est ce qui explique la pr√©sence de quelques ombres √©cras√©es.
        
        En comparant les histogrammes de zones dynamiques lin√©aires √† ceux sRGB, on constate l'effet de la correction gamma, 
        soit de d√©placer les valeurs vers le centre de l'histogramme, plus pr√®s de ce que per√ßoit l'oeil.
        
        Le nombre de stops de la plage dynamique est une unit√© logarithmique servant √† quantifier le nombre de fois 
        o√π le pixel le plus clair est plus lumineux que le plus sombre. Donc un nombre de stop faibles indique que la sc√®ne est √©clair√©e de mani√®re assez uniforme.
        
        DISCUSSION SUR LA COMPRESSION JPEG √Ä DIFF√âRENTES QUALIT√âS
        Vue de loin, la compression JPEG, meme √† des niveaux √©lev√©s (jusqu'√† 25%), ne modifie pas de mani√®re perceptible l'image.
        Toutefois, en zoomant, on voit bien l'effet de la compression. 
        Dans un certain sens, parfois, la compression adoucit l'image, ce qui permet de masquer les 
        autres artefacts apparus √† d'autres √©tapes du pipeline de transformation des photos. C'est ce qui se passe pour a0011-DSC_0082, 
        qui √† mon avis souffre tr√®s peu du 75% de compression pour cette raison. 
         
        Les qualit√©s de compression plus faibles introduisent des artefacts de bloc et une perte de finesse, 
        particuli√®rement visibles dans les zones textur√©es et les d√©grad√©s, bien que m√™me √† 25% de compression, 
        les images me paraissent tout de m√™me √©tonamment nettes.
        
        Finalement, le graphique montre bien qu'il vaut la peine de compresser en jpeg si on veut √©conomiser de l'espace, 
        et ce jusqu'√† environ 75% de qualit√©. 
        Plus bas, les gains en taille de fichier sont beaucoup plus faibles, pour des pertes de qualit√© importantes.
        
        Ma conclusion serait donc qu'une compression de 75% en jpeg est optimale.
            """)
    sec4_content += subsection(
        "Analyse et observations",
        make_styled_paragraphs(sec4_raw_analyse_text)
    )

    content += section("Section 4: Mappage Tonal et Encodage d'Affichage", sec4_content, icon="üé®")

    # =============================================================================
    # GRILLE DE COMPARAISON DES IMAGES FINALES
    # =============================================================================
    # Collecter toutes les images finales JPG de la section 4 et leurs r√©f√©rences
    comparisons = []
    jpg_files = sorted(glob.glob(os.path.join(sec4_dir, "*_final.jpg")))

    for jpg_path in jpg_files:
        basename = os.path.basename(jpg_path).replace("_final.jpg", "")
        final_src = os.path.basename(jpg_path)

        # Chercher l'image de r√©f√©rence correspondante
        reference_src = None
        srgb_path = os.path.join(sec1_dir, f"{basename}_srgb.jpg")
        if os.path.exists(srgb_path):
            reference_src = f"../images_intermediaires_sec1/{basename}_srgb.jpg"

        if reference_src:
            comparisons.append({
                "basename": basename,
                "final_src": final_src,
                "reference_src": reference_src,
                "final_alt": f"Image finale - {basename}",
                "reference_alt": f"R√©f√©rence sRGB - {basename}"
            })
        else:
            # Si pas de r√©f√©rence, ajouter quand m√™me l'image finale seule
            comparisons.append({
                "basename": basename,
                "final_src": final_src,
                "reference_src": final_src,  # Dupliquer pour l'affichage
                "final_alt": f"Image finale - {basename}",
                "reference_alt": f"Image finale - {basename}"
            })

    if comparisons:
        grid_content = subsection(
            "Comparaison: Vos r√©sultats vs R√©f√©rences sRGB",
            '<p style="color: #a0a0a0; margin-bottom: 20px;">Comparez vos images finales avec les aper√ßus sRGB g√©n√©r√©s par rawpy. Cliquez sur une image pour l\'agrandir.</p>'
        )
        grid_content += comparison_grid(comparisons)
        content += section("Comparaison des Images Finales", grid_content, icon="üñºÔ∏è")

    # =============================================================================
    # CONCLUSION G√âN√âRALE
    # =============================================================================
    raw_conclusion_text = textwrap.dedent("""
    Le mappage tonal est n√©cessaire pour afficher correctement une image dont la plage dynamique d√©passe celle des √©crans.
    Il compresse les valeurs lin√©aires captur√©es par le capteur en valeurs adapt√©es √† l‚Äôaffichage, en pr√©servant d√©tails et contraste.

    Afin de pr√©parer l'image pour le mappage tonal, il faut d'abord ajuster sa luminosit√©, 
    pour exclure des futurs calculs les valeurs extr√™mement lumineuses, qui seraient aberrantes. 
    Dans ce TP, la mani√®re de faire a √©t√© d'utiliser le 99·µâ percentile d'intensit√© pour diviser les images par cette valeur.

    Ensuite, plusieurs op√©rateurs sont possibles. Ils peuvent √™tre lin√©aires (simple normalisation, rapide mais √©crase les hautes lumi√®res) 
    ou Reinhard (non lin√©aire, compresse les hautes lumi√®res tout en conservant les d√©tails dans les ombres).

    L‚ÄôOETF sRGB applique une correction gamma pour adapter les valeurs lin√©aires √† la perception humaine, 
    renfor√ßant la luminosit√© per√ßue dans les tons moyens.

    L‚Äôanalyse de la plage dynamique permet d‚Äô√©valuer si les d√©tails dans les zones tr√®s claires 
    ou tr√®s sombres sont pr√©serv√©s et si le mappage tonal est efficace.
        """
                                          )
    conclusion_content = subsection(
        "Conclusion",
        make_styled_paragraphs(raw_conclusion_text)
    )

    content += section("Conclusion", conclusion_content, icon="üìù")

    # G√©n√©rer le document HTML final
    html = html_document(
        "Rapport TP1 - Roxanne Maheu",
        "",
        "üì∏",
        content,
        accent_color="#778da9",
    )

    save_report(html, os.path.join(output_dir, "rapport_complet.html"))


# =============================================================================
# Traitement Principal
# =============================================================================


def process_display_encoding(
        input_dir="images_intermediaires_sec3",
        output_dir="images_intermediaires_sec4",
        input_suffix="_camera_xyz.tiff",
):
    """Traiter les images XYZ avec mappage tonal et encodage d'affichage."""
    os.makedirs(output_dir, exist_ok=True)

    tiff_files = sorted(glob.glob(os.path.join(input_dir, f"*{input_suffix}")))

    if not tiff_files:
        print(f"Aucun fichier *{input_suffix} trouv√© dans {input_dir}/")
        return

    print(f"\n{'#' * 60}")
    print("# Section 4: Mappage Tonal et Encodage d'Affichage")
    print(f"{'#' * 60}")
    print(f"\n{len(tiff_files)} fichier(s) trouv√©(s)")

    # G√©n√©rer la figure des courbes une seule fois
    create_tonemapping_curves_figure(os.path.join(output_dir, "tonemapping_curves.png"))

    results = []

    global_jpeg_sizes = defaultdict(list)
    global_png_sizes = []

    for tiff_path in tiff_files:
        basename = os.path.basename(tiff_path).replace(input_suffix, "")

        print(f"\n{'=' * 60}")
        print(f"Traitement: {basename}")
        print("=" * 60)

        try:
            xyz_image = load_tiff(tiff_path)
            result = {"basename": basename}

            # Ajustement de luminosit√© (√† impl√©menter par l'√©tudiant)
            print("  [0] Ajustement de luminosit√©...")
            xyz_image = adjust_brightness(xyz_image, percentile=99)

            # Comparaison des op√©rateurs de mappage tonal
            print("  [A] Comparaison du mappage tonal...")
            tonemap_funcs = {
                "Lin√©aire": tonemap_linear,
                "Reinhard": tonemap_reinhard,
            }
            srgb_results = create_tonemapping_comparison_figure(
                xyz_image,
                os.path.join(output_dir, f"{basename}_tonemapping_comparison.png"),
                tonemap_funcs,
                xyz_to_linear_srgb,
                linear_to_srgb,
                title=f"Mappage tonal - {basename}",
            )

            # Utiliser Reinhard pour la suite
            xyz_tonemapped = tonemap_reinhard(xyz_image)
            rgb_linear = xyz_to_linear_srgb(xyz_tonemapped)
            rgb_linear = np.clip(rgb_linear, 0, 1)
            srgb = linear_to_srgb(rgb_linear)

            # Sauvegarder les r√©sultats
            for name, img in srgb_results.items():
                save_tiff16(
                    img, os.path.join(output_dir, f"{basename}_{name.lower()}.tiff")
                )

            # Comparaison OETF
            print("  [B] Comparaison OETF...")
            create_oetf_comparison_figure(
                rgb_linear,
                srgb,
                os.path.join(output_dir, f"{basename}_oetf_comparison.png"),
                title=f"OETF sRGB - {basename}",
            )

            # Sauvegarder l'image finale en JPEG
            print("  [C] Sauvegarde de l'image finale...")
            img_8bit = quantize_to_8bit(srgb)

            final_jpg = os.path.join(output_dir, f"{basename}_final.jpg")
            save_jpeg(img_8bit, final_jpg, quality=95)

            # Analyse des artefacts JPEG vs le png de r√©f√©rence
            print("  [D] Analyse des artefacts JPEG...")
            jpeg_analysis = analyze_jpeg_artifacts(img_8bit, output_dir, basename)

            for q, size in jpeg_analysis["jpeg_sizes_Ko"].items():
                global_jpeg_sizes[q].append(size)
            png_size = os.path.getsize(jpeg_analysis["png_path"]) / 1024.0
            global_png_sizes.append(png_size)

            zoom_images = {"PNG": jpeg_analysis["png_path"]}
            zoom_images.update({
                f"JPEG q{q}": os.path.join(output_dir, f"{basename}_q{q}.jpg")
                for q in jpeg_analysis["jpeg_sizes_Ko"].keys()
            })

            edge_pos = find_edge_region(img_8bit)
            center_pos = (img_8bit.shape[0] // 2, img_8bit.shape[1] // 2)

            create_jpeg_zoom_figure(
                zoom_images,
                os.path.join(output_dir, f"{basename}_jpeg_zoom.png"),
                edge_pos=edge_pos,
                center_pos=center_pos,
                zoom_size=150,
                title=f"Zoom sur artefacts JPEG - {basename}"
            )

            result["jpeg_analysis"] = jpeg_analysis

            # Analyse de plage dynamique
            print("  [E] Analyse de plage dynamique...")
            dr_analysis = analyze_dynamic_range(rgb_linear)
            result["dynamic_range"] = dr_analysis
            print(
                f"    Plage dynamique: {dr_analysis['dynamic_range_stops']:.1f} stops"
            )

            create_dynamic_range_figure(
                rgb_linear,
                srgb,
                dr_analysis,
                os.path.join(output_dir, f"{basename}_dynamic_range.png"),
                title=f"Plage dynamique - {basename}",
            )

            results.append(result)

        except Exception as e:
            print(f"\nErreur lors du traitement de {tiff_path}: {e}")
            import traceback

            traceback.print_exc()

    if global_jpeg_sizes:
        plot_global_jpeg_size_vs_quality(
            global_jpeg_sizes,
            global_png_sizes,
            os.path.join(output_dir, "jpeg_size_vs_quality_global_mean.png"),
        )

    if results:
        generate_report(results, output_dir)

    print(f"\n{'=' * 60}")
    print(f"Termin√©! {len(results)} image(s) trait√©e(s) ‚Üí {output_dir}/")
    print("=" * 60)


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="TP1 Section 4: Mappage Tonal et Encodage"
    )
    parser.add_argument("--input-dir", "-i", default="images_intermediaires_sec3")
    parser.add_argument("--output-dir", "-o", default="images_intermediaires_sec4")
    parser.add_argument("--suffix", "-s", default="_camera_xyz.tiff")

    args = parser.parse_args()
    process_display_encoding(args.input_dir, args.output_dir, args.suffix)
